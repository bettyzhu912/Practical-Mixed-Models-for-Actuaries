---
title: 'Practical Mixed Models for Actuaries'
subtitle: 'Code Chuncks Extracted via AWK script'
author: 'Ernesto Schirmacher'
output: html_notebook
---

## Chapter 6--Applications

```{r}
#| include: true
#| message: false

library(patchwork)
library(statmod)
library(gamlss)
library(MASS)
library(dhglm)
library(kableExtra)
library(tidyverse)
```

```{r}
#| echo: true
#| label: load-mass-bi-data

data("usmassBI2", package = "CASdatasets")
```

```{r}
#| echo: true
#| label: compute-usmassBI2-descriptive-statistics

tb <- usmassBI2 |>
  group_by(YEAR) |>
  summarize("Mean" = mean(AC),
            "Median" = median(AC),
            "Std. Deviation" = sd(AC),
            "Minimum" = min(AC),
            "Maximum" = max(AC)) |>
  pivot_longer(cols = 2:6, 
               names_to = "measure",
               values_to = "value") |>
  pivot_wider(names_from = YEAR,
              values_from = value)
```

```{r}
#| echo: true
#| label: tbl-usmass-bi-descriptive-statistics
#| tbl-cap: "Descriptive statistics for average claims per unit of exposure for a random sample of 29 towns in Massachusetts. Dollar amounts have been restated to 1991 using the consumer price index."

tb |>
  kbl(booktabs = TRUE,
      col.names = c("", 1993:1998),
      digits = c(0, rep(2, 6))) |>
  add_header_above(c(" ", "Average Claim Amount" = 6)) |>
  kable_classic()
rm(tb)
```

```{r}
#| echo: true
#| label: fig-usmass-bi-multiple-time-series-plot
#| fig-cap: "Multiple time series plot of avearge claim per unit of exposure. Each time series corresponds to one of the 29 towns in the data. The red dots joined by pink lines correspond to town code 35, which has some of the highest average claims during the first couple of years. The blue points joined by light blue lines correspond to town code 53, which has some of the lowest average claims."
ggplot(data = filter(usmassBI2,
                     TOWNCODE != 35 & TOWNCODE != 53),
       mapping = aes(x = YEAR,
                     y = AC,
                     group = TOWNCODE)) +
  geom_line(color = "gray") +
  geom_point(color = "darkgray") +
  geom_line(data = filter(usmassBI2,
                          TOWNCODE == 35),
            mapping = aes(x = YEAR,
                          y = AC),
            color = "pink") +
  geom_point(data = filter(usmassBI2,
                           TOWNCODE == 35),
             mapping = aes(x = YEAR,
                           y = AC),
             color = "red") +
  geom_line(data = filter(usmassBI2,
                          TOWNCODE == 53),
            mapping = aes(x = YEAR,
                          y = AC),
            color = "lightblue") +
  geom_point(data = filter(usmassBI2,
                           TOWNCODE == 53),
             mapping = aes(x = YEAR,
                           y = AC),
             color = "blue") +
  labs(x = "Calendar Year",
       y = "Average Claim")
```

```{r}
#| echo: true
#| label: fig-umass-bi-average-claim-by-pci-and-ppsm
#| fig-cap: "Average claim sizes by per capita income (in thousands of dollars) and population per square mile (in log base 10 scale). The red colored points correspond to town code 35 and the blue colored points correspond to town code 53."
p <- ggplot(data = filter(usmassBI2,
                          TOWNCODE != 35 & TOWNCODE != 53),
            mapping = aes(x = PCI / 1000,
                          y = AC)) +
  geom_point(color = "darkgray") +
  geom_point(data = filter(usmassBI2,
                           TOWNCODE == 35),
             mapping = aes(x = PCI / 1000,
                           y = AC),
             color = "red") +
  geom_point(data = filter(usmassBI2,
                           TOWNCODE == 53),
             mapping = aes(x = PCI / 1000,
                           y = AC),
             color = "blue") +
  labs(x = "Per Capita Income ($000)",
       y = "Average Claim Cost") +
  theme(legend.position = "none")

q <- ggplot(data = filter(usmassBI2,
                          TOWNCODE != 35),
            mapping = aes(x = log(PPSM),
                          y = AC)) +
  geom_point(color = "darkgray") +
  geom_point(data = filter(usmassBI2,
                           TOWNCODE == 35),
             mapping = aes(x = log(PPSM),
                           y = AC),
             color = "red") +
  geom_point(data = filter(usmassBI2,
                           TOWNCODE == 53),
             mapping = aes(x = log(PPSM),
                           y = AC),
             color = "blue") +
  labs(x = "Population per Sq. Mile (log-scale)",
       y = "Average Claim Cost") +
  theme(legend.position = "none")
p + q
rm(p, q)
```

```{r}
#| echo: true
#| label: fig-usmass-bi-average-claim-histogram-and-density
#| fig-cap: "Histogram of average claim costs along with a non-parametric estimate of the density function (solid line) and a normal density function (dashed line) chosen to match the empirical mean and standard deviation across all towns and all years."

ggplot(data = usmassBI2,
       mapping = aes(x = AC)) +
  geom_histogram(aes(y = after_stat(density)), bins = 30, fill = "grey") +
  geom_density(linewidth = 0.75) +
  geom_line(data = tibble(x = seq(25, 275, length = 100),
                          y = dnorm(x, mean = 137.32, sd = 35.18)),
            mapping = aes(x = x, y = y),
            color = "blue",
            linetype = "dashed",
            linewidth = 0.75) +
  labs(x = "Average Claim Cost",
       y = "Density")
```

```{r}
#| echo: true
#| label: usmass-bi-transform-variables-and-create-subset

usmassBI2 <- usmassBI2 |>
  mutate(YR = YEAR - 1992,
         lnPPSM = log(PPSM),
         PCI.k = PCI / 1000)

db.train <- usmassBI2 |>
  filter(YEAR < 1998)
db.test <- usmassBI2 |>
  filter(YEAR == 1998)
```

```{r}
#| echo: true
#| label: usmass-bi-pooled-model

bi.all <- lm(AC ~ PCI.k + lnPPSM + YR,
             data = db.train)
summary(bi.all)
```

```{r}
#| include: true
#| label: usmass-bi-compute-diagnostics-bi.all

db.train <- db.train |>
  mutate(bi.all.mu = predict(bi.all),
         bi.all.rS = rstandard(bi.all))
```

```{r}
#| echo: true
#| message: false
#| label: fig-usmass-bi-diagnostic-plots-bi-all-one
#| fig-cap: "Diagnostic plots for model `bi.all`.  Left-hand panel shows stadardized residuals versus fitted values and the right-hand panel is the absolute value of the standardized residuals against the fitted values. The blue line in each panel is a scatterplot smooth showing the overall trend of the points."

p1 <- ggplot(data = db.train,
             mapping = aes(x = bi.all.mu,
                           y = bi.all.rS)) +
  geom_point() +
  geom_smooth(se = TRUE) +
  labs(x = "Fitted Values",
       y = "Standardized Residuals")
p2 <- ggplot(data = db.train,
             mapping = aes(x = bi.all.mu,
                           y = abs(bi.all.rS))) +
  geom_point() +
  geom_smooth(se = TRUE) +
  labs(x = "Fitted Values",
       y = "|Standardized Residuals|")
(p1 + p2)
```

```{r}
#| echo: true
#| message: false
#| label: fig-usmass-bi-diagnostic-plots-bi-all-two
#| fig-cap: "Diagnostic plots for model `bi.all`. Each panel shows the standardized residuals against a predictor variable.  The blue line in each panel shows the overall trend of points."

p1 <- ggplot(data = db.train,
             mapping = aes(x = YEAR,
                           y = bi.all.rS)) +
  geom_point() +
  geom_smooth(se = TRUE) +
  labs(x = "Calendar Year",
       y = "Standardized Residuals")
p2 <- ggplot(data = db.train,
             mapping = aes(x = PCI.k,
                           y = bi.all.rS)) +
  geom_point() +
  geom_smooth(se = TRUE) +
  labs(x = "Per Capita Income ($000)",
       y = "Standardized Residuals")

p3 <- ggplot(data = db.train,
             mapping = aes(x = lnPPSM,
                           y = bi.all.rS)) +
  geom_point() +
  geom_smooth(se = TRUE) +
  labs(x = "Log Population per Square Mile",
       y = "Standardized Residuals")
(p1 + p2) / (p3 + (plot_spacer() + 
                     theme(plot.margin = unit(c(0,0,0,33), "pt"))))
rm(p1, p2, p3)
```

```{r}
#| echo: true
#| label: usmass-bi-split-the-data-for-each-town

twns <- unique(as.character(db.train$TOWNCODE))
twn.db <- map(twns, 
              \(x) filter(db.train, TOWNCODE == x) |>
                select(AC, PCI.k, lnPPSM, YR, YEAR, TOWNCODE))
names(twn.db) <- twns
```

```{r}
#| echo: true
#| label: usmass-bi-compute-individual-linear-models-for-each-town

twns.lm <- map(twn.db,
               \(d) lm(AC ~ PCI.k + lnPPSM + YR,
                       data = d))
```

```{r}
#| echo: true
#| label: usmass-bi-compute-r-squared-for-individual-fits

map_dbl(twns.lm, 
        \(x) summary(x)$r.squared) |>
  sort() |>
  round(3)
```

```{r}
#| include: true
#| label: usmass-bi-grab-data-low-mid-high-r-squared

tb <- bind_rows(bind_cols(twn.db[["50"]], mu = predict(twns.lm[["50"]])),
                bind_cols(twn.db[["39"]], mu = predict(twns.lm[["39"]])),
                bind_cols(twn.db[["42"]], mu = predict(twns.lm[["42"]])),
                
                bind_cols(twn.db[["17"]], mu = predict(twns.lm[["17"]])),
                bind_cols(twn.db[["52"]], mu = predict(twns.lm[["52"]])),
                bind_cols(twn.db[["13"]], mu = predict(twns.lm[["13"]])),
                
                bind_cols(twn.db[["32"]], mu = predict(twns.lm[["32"]])),
                bind_cols(twn.db[["11"]], mu = predict(twns.lm[["11"]])),
                bind_cols(twn.db[["36"]], mu = predict(twns.lm[["36"]])))
tb$TOWNCODE <- fct_drop(tb$TOWNCODE)
tb$TOWNCODE <- fct_relevel(tb$TOWNCODE,
                           c("32","11","36","17","52","13","50","39","42"))
```

```{r}
#| echo: true
#| label: fig-usmass-bi-low-mid-high-r-squared-regressions
#| fig-cap: "Actual versus predicted average claim costs from the regression lines fitted to each town individually. Towns 32, 11, and 36 have the highest $R^2$ values and towns 50, 39, and 42 have the lowest values.  Towns 17, 52, and 13 are in the middle when $R^2$ measures are sorted. The panels are arranged from the lowest $R^2$ in the bottom left-hand corner to the highest $R^2$ value in the top right-hand corner. The gray line in each panel represents the line of perfect fit $(y = x)$."

ggplot(data = tb,
       mapping = aes(x = AC,
                     y = mu)) +
  geom_point() +
  geom_abline(slope = 1,
              color = "gray") +
  labs(x = "Actual Average Claim Cost",
       y = "Expected Average Claim Cost") +
  facet_wrap(vars(TOWNCODE),
             scales = "free")
rm(tb)
```

```{r}
#| echo: true
#| label: usmass-bi-fixed-effects-model

bi.fixed <- lm(AC ~ TOWNCODE + PCI.k + lnPPSM + YR,
               data = db.train)
summary(bi.fixed)
```

```{r}
#| echo: true
#| label: us-mass-random-intercept-model

bi.rnd.int <- lme(AC ~ PCI.k + lnPPSM + YR,
               data = db.train,
               random = ~ 1 | TOWNCODE)
summary(bi.rnd.int)
```

```{r}
#| echo: true
#| label: fig-usmass-bi-lme-model-random-intercepts-fv-versus-residuals
#| fig-cap: "Standardized residuals versus fitted values for the random intercept model fitted to the sample of Massachusetts towns."

plot(bi.rnd.int)
```

```{r}
#| label: usmass-bi-confidence-intervals-for-random-effects-models

intervals(bi.rnd.int)
```

```{r}
#| echo: true
#| label: usmass-bi-random-slope-model

bi.rnd.slope <- lme(AC ~ PCI.k + lnPPSM + YR,
                    data = db.train,
                    random = ~ 1 + YR | TOWNCODE)
intervals(bi.rnd.slope)
```

```{r}
#| echo: true
#| label: usmass-bi-random-slopes-summary

summary(ranef(bi.rnd.slope)[["YR"]])
```

```{r}
#| include: true
#| label: usmass-bi-gather-models

bi.models <- list(bi.all,
                  bi.fixed,
                  bi.rnd.int,
                  bi.rnd.slope)
```

```{r}
#| include: true
#| label: usmass-bi-compute-predictions-from-all-models

db.train <- db.train |>
  mutate(bi.all.mu = predict(bi.all),
         bi.fixed.mu = predict(bi.fixed),
         bi.rnd.int.mu = predict(bi.rnd.int),
         bi.rnd.slope.mu = predict(bi.rnd.slope))

db.test <- db.test |>
  mutate(bi.all.mu = predict(bi.all, 
                             newdata = db.test),
         bi.fixed.mu = predict(bi.fixed, 
                               newdata = db.test),
         bi.rnd.int.mu = predict(bi.rnd.int, 
                                 newdata = db.test),
         bi.rnd.slope.mu = predict(bi.rnd.slope, 
                                   newdata = db.test))
```

```{r}
#| include: true
#| label: usmass-bi-performance-measurement-functions

MSPE <- function(x, y) (mean((x - y)^2))
MAPE <- function(x, y) mean(abs(x - y))
```

```{r}
#| include: true
#| label: usmass-bi-compute-performance-statistics

tb <- tibble(model = c("bi.all", "bi.fixed", "bi.rnd.int", "bi.rnd.slope"),
             AIC.in = map_dbl(bi.models,
                              \(x) AIC(x)),
             BIC.in = map_dbl(bi.models,
                              \(x) BIC(x)),
             MSPE.in = c(MSPE(db.train$AC, db.train$bi.all.mu),
                         MSPE(db.train$AC, db.train$bi.fixed.mu),
                         MSPE(db.train$AC, db.train$bi.rnd.int.mu),
                         MSPE(db.train$AC, db.train$bi.rnd.slope.mu)),
             MAPE.in = c(MAPE(db.train$AC, db.train$bi.all.mu),
                         MAPE(db.train$AC, db.train$bi.fixed.mu),
                         MAPE(db.train$AC, db.train$bi.rnd.int.mu),
                         MAPE(db.train$AC, db.train$bi.rnd.slope.mu)),
             MSPE.out = c(MSPE(db.test$AC, db.test$bi.all.mu),
                          MSPE(db.test$AC, db.test$bi.fixed.mu),
                          MSPE(db.test$AC, db.test$bi.rnd.int.mu),
                          MSPE(db.test$AC, db.test$bi.rnd.slope.mu)),
             MAPE.out = c(MAPE(db.test$AC, db.test$bi.all.mu),
                          MAPE(db.test$AC, db.test$bi.fixed.mu),
                          MAPE(db.test$AC, db.test$bi.rnd.int.mu),
                          MAPE(db.test$AC, db.test$bi.rnd.slope.mu)))
```

```{r}
#| echo: true
#| label: tbl-usmass-bi-performance-table
#| tbl-cap: "Comparison metrics for all four model using both the training as well as the validation data. AIC is the Akaike information criterion, BIC is the Bayesian information criterion, MSPE is the mean squared prediction error and MAPE is the mean absolute prediction error."

tb |>
  kbl(booktabs = TRUE,
      digits = c(0, rep(2, 6)),
      format.args = list(big.mark = ","),
      col.names = c("Model", "AIC", "BIC", "MSPE", "MAPE", "MSPE", "MAPE")) |>
  add_header_above(c(" " = 1, "Training Data" = 4, "Validation Data" = 2)) |>
  kable_classic()
rm(tb)
```

```{r}
#| include: true
#| label: bi-usmass-compute-data-for-actual-vs-expected-rnd-int-model

gap <- 0.2
db.all <- bind_rows(db.train, db.test)
db.all <- db.all |>
  mutate(YEAR = ifelse(YEAR == 1998, 1998 - gap, YEAR))
db.tmp <- db.test
db.tmp <- bind_rows(db.tmp, db.tmp)
db.tmp[1:29, "YEAR"] <- 1998 - gap
db.tmp[30:58, "YEAR"] <- 1998 + gap
db.tmp[30:58, "AC"] <- db.tmp[1:29, "bi.rnd.int.mu"]

rm(gap)
```

```{r}
#| echo: true
#| label: fig-bi-usmass-actual-vs-expected-rnd-int-model
#| fig-cap: "Time series plot of the actual claim costs across calendar years for the 29 randomly selected towns of Massachusetts (shown in black) for the training data (1993--1997). The actual 1998 experience is shown in gray along with the predicted values from the random intercept model (shown in red)."

ggplot(data = db.all,
       mapping = aes(x = YEAR,
                     y = AC,
                     group = TOWNCODE)) +
  geom_line(color = "gray") +
  geom_line(data = db.tmp,
             mapping = aes(x = YEAR,
                           y= AC,
                           group = TOWNCODE),
             color = "pink") +
  geom_point() +
  geom_point(data = db.tmp[1:29,],
             mapping = aes(x = YEAR,
                           y = AC,
                           group = TOWNCODE),
             color = "gray") +
  geom_point(data = db.tmp[30:58,],
             mapping = aes(x = YEAR,
                           y = AC,
                           group = TOWNCODE),
             color = "red",
             pch = 1) +
  labs(x = "Calendar Year",
       y = "Average Claim Costs")

rm(db.all, db.tmp)
```

```{r}
#| include: true
#| label: load-arizona-medicare-data

db <- read_csv("medpar.csv",
               col_types = "fiiiiiiiii")
db <- db |>
  mutate(type = case_when(type1 == 1 ~ "Elective",
                          type2 == 1 ~ "Urgent",
                          type3 == 1 ~ "Emergency"))
db$type <- factor(db$type, 
                  levels = c("Elective", "Urgent", "Emergency"))
```

```{r}
#| include: true
#| label: compute-los-summary-by-provider

tb <- db |>
  group_by(provnum) |>
  summarize(sz = n(),
            mean.los = mean(los),
            mean.age = mean(age),
            count.white = sum(white),
            count.type1 = sum(type1),
            count.type2 = sum(type2),
            count.type3 = sum(type3)) |>
  arrange(desc(mean.los))
```

```{r}
#| label: los-zero-truncated-probabilities-example

f <- function(mu = 1.5, x = 0:9, zp = FALSE) {
  lambda <- mu
  if(zp) {
    lambda <- mu + pracma::lambertWp(-mu * exp(-mu))
  }
  ans <- tibble(x = x,
                prob = dpois(x, lambda = lambda))
  if (zp) {
    
    ans$prob <- ans$prob / (1 - exp(-lambda))
    ans <- filter(ans, x > 0)
  }
  return(ans)
}
```

```{r}
#| echo: true
#| label: fig-los-zero-truncated-probabilities-comparison
#| fig-cap: "Poisson and Zero-truncated Poisson probabilities for means equal to 1.5, 2.5, and 3.5. As the mean increases, the difference between the Poisson and the Zero-Truncated Poisson distributions narrows quickly. The filled in circles represent the Poisson distribution and the open circles correspond to the Zero-Truncated Poisson distribution. Red colored points correspond to a mean of 1.5, blue corresponds to 2.5, and purple has mean of 3.5."

ggplot(mapping = aes(x = x,
                     y = prob)) +
  geom_line(data = f(1.5), color = "gray") +
  geom_point(data = f(1.5), color = "red") +
  geom_line(data = f(1.5, zp = TRUE), color = "gray") +
  geom_point(data = f(1.5, zp = TRUE), color = "red", pch = 1) +
  geom_line(data = f(2.5), color = "gray") +
  geom_point(data = f(2.5), color = "blue") +
  geom_line(data = f(2.5, zp = TRUE), color = "gray") +
  geom_point(data = f(2.5, zp = TRUE), color = "blue", pch = 1) +
  geom_line(data = f(3.5), color = "gray") +
  geom_point(data = f(3.5), color = "purple") +
  geom_line(data = f(3.5, zp = TRUE), color = "gray") +
  geom_point(data = f(3.5, zp = TRUE), color = "purple", pch = 1) +
  scale_x_continuous(breaks = seq(0, 8, by = 2), 
                     labels = seq(0, 8, by = 2)) +
  labs(x = "Random Variable",
       y = "Probability")
rm(f)
```

```{r}
#| echo: true
#| label: tbl-los-summary-by-provider
#| tbl-cap: "Top 5 and bottom 5 providers sorted by mean length of stay in decreasing order. Also showing the number of patients for each provider, their mean age group, and the number of patients who consider themselves Caucasian, and the number by type of admission to the hospital."

tb[c(1:5, 50:54),] |>
  kbl(booktabs = TRUE,
      col.names = c("Provider", "Patients", "of Stay", "Age Group", 
                    "White", "Elective", "Urgent", "Emergency"),
      digits = c(0,0,1,1,0,0,0,0),
      align = rep("r", 8)) |>
  add_header_above(c(" " = 1, "Number of" = 1, "Mean Length" = 1, 
                     "Mean" = 1, "Count of" = 1, "Type of Admission" = 3),
                   line = FALSE,
                   align = c(rep("r", 5), "c")) |>
  kable_classic()
```

```{r}
#| echo: true
#| label: tbl-los-average-los-by-age-group-and-type-of-admission
#| tbl-cap: "Average length of stay by age group and type of admission. Note that in nearly all cases elective admissions are shortest and emergency admission are the longest."

db |>
  group_by(age, type) |>
  summarize(mn.los = round(mean(los),1),
            .groups = "drop") |>
  pivot_wider(names_from = type,
              values_from = mn.los) |>
  kbl(booktabs = TRUE,
      digits = c(0, 1, 1, 1),
      col.names = c("Age Group", "Elective", "Urgent", "Emergency")) |>
  add_header_above(c(" " = 1, "Type of Admission" =  3)) |>
  kable_classic()
```

```{r}
#| echo: true
#| label: los-boxplot-age-versus-length-of-stay

ggplot(data = db,
       mapping = aes(x = factor(age),
                     y = los)) +
  facet_wrap(~ type) +
  geom_boxplot() +
  labs(x = "Age Group",
       y = "Length of Stay (days)")
```

```{r}
#| include: true
#| label: los-create-age-as-categorical

db <- db |>
  mutate(age.cat = factor(age,
                          levels = c(6, 1:5, 7:9)))
```

```{r}
#| echo: true
#| label: los-poisson-model-main-effects

los.pois <- glm(los ~ type + white + hmo + age.cat,
                data = db,
                family = poisson(link = "log"))
summary(los.pois)
```

```{r}
#| include: true
#| label: los-poisson-compute-diagnostics

db2 <- db |>
  mutate(mu = predict(los.pois, type = "response"),
         rD = resid(los.pois, type = "deviance"),
         rQ = qresid(los.pois))
```

```{r}
#| echo: true
#| label: fig-los-poisson-diagnostics
#| fig-cap: "Diagnostic plots for the Poisson model predicting length of stay based on type of admission, self-reported race, age category, and whether or not the patient is a member of a health maintenance organization. The clusters, from left to right in the upper panels, correspond to elective, urgent, and emergency admissions to the hospital."

p <- ggplot(data = db2,
            mapping = aes(x = mu, y = rD,
            color = type)) +
  geom_point(alpha = 0.4) + 
  labs(x = "Fitted Values",
       y = "Deviance Residuals") +
  theme(legend.position = "none")
q <- ggplot(data = db2,
            mapping = aes(x = mu, y = abs(rD),
                          color = type)) +
  geom_point(alpha = 0.4) + 
  labs(x = "Fitted Values",
       y = "|Deviance Residuals|") +
  theme(legend.position = "none")
r <- ggplot(data = db2,
       mapping = aes(sample = rD)) +
  geom_qq() + geom_qq_line() +
  labs(x = "Theoretical Quantiles",
       y = "Sample Quantiles")
s <- ggplot(data = db2,
            mapping = aes(x = rD)) +
  geom_histogram() +
  labs(x = "Deviance Residuals")
(p + q) / (r + s)
```

```{r}
#| include: false
#| label: los-clean-up-env-1

rm(p, q, r, s)
```

```{r}
#| include: false
#| label: los-clean-up-env-2

rm(db2)
```

```{r}
#| echo: true
#| label: los-estimates-of-dispersion-parameter

c("Mean Dev. Estimate" = deviance(los.pois) / df.residual(los.pois),
  "Pearson Estimate" = sum(resid(los.pois, type = "pearson")^2) / 
    df.residual(los.pois))
```

```{r}
#| echo: true
#| label: los-remove-top-5-pct-and-refit-model

dta <- filter(db, 
              db$los < quantile(db$los, probs = 0.95))
los.pois.no <- glm(los ~ type + white + hmo + age.cat,
                data = dta,
                family = poisson(link = "log"))
summary(los.pois.no)
```

```{r}
#| include: true
#| label: los-poisson-compute-diagnostics-no-outliers

dta2 <- dta |>
  mutate(mu = predict(los.pois.no, type = "response"),
         rD = resid(los.pois.no, type = "deviance"))
```

```{r}
#| echo: true
#| label: los-poisson-diagnostics-no-outliers

p <- ggplot(data = dta2,
            mapping = aes(x = mu, y = rD,
            color = type)) +
  geom_point(alpha = 0.4) + 
  labs(x = "Fitted Values",
       y = "Deviance Residuals") +
  theme(legend.position = "none")
q <- ggplot(data = dta2,
            mapping = aes(x = mu, y = abs(rD),
                          color = type)) +
  geom_point(alpha = 0.4) + 
  labs(x = "Fitted Values",
       y = "|Deviance Residuals|") +
  theme(legend.position = "none")
r <- ggplot(data = dta2,
       mapping = aes(sample = rD)) +
  geom_qq() + geom_qq_line() +
  labs(x = "Theoretical Quantiles",
       y = "Sample Quantiles")
s <- ggplot(data = dta2,
            mapping = aes(x = rD)) +
  geom_histogram() +
  labs(x = "Deviance Residuals")
(p + q) / (r + s)
```

```{r}
#| echo: true
#| label: los-estimates-of-dispersion-parameter-no-outliers

c("Mean Dev. Estimate" = deviance(los.pois.no) / df.residual(los.pois.no),
  "Pearson Estimate" = sum(resid(los.pois.no, type = "pearson")^2) / 
    df.residual(los.pois.no))
```

```{r}
#| include: false
#| label: los-clean-up-env-3

rm(dta, los.pois.no, dta2, p, q, r, s)
```

```{r}
#| echo: true
#| label: los-generate-new-dataset

set.seed(12853)
N <- 100
dta <- tibble(skip = c(rpois(N, lambda = 4.5),
                       rpois(N, lambda = 2.5),
                       rpois(N, lambda = 1.5),
                       rpois(N, lambda = 6.5)),
              class = c(rep("freshman", N),
                        rep("sophomore", N),
                        rep("junior", N),
                        rep("senior", N)))
```

```{r}
#| echo: true
#| label: los-fit-null-glm-model

m1 <- glm(skip ~ 1,
          data = dta,
          family = poisson(link = "log"))
(phi.hat <- sum(resid(m1, type = "pearson")^2) / df.residual(m1))
```

```{r}
#| echo: true
#| label: los-fit-glm-model-with-class-predictor

m2 <- glm(skip ~ class,
          data = dta,
          family = poisson(link = "log"))
(phi.hat <- sum(resid(m2, type = "pearson")^2) / df.residual(m2))
```

```{r}
#| include: false
#| label: los-clean-up-env-4

rm(N, dta, m1, m2, phi.hat)
```

```{r}
#| echo: true
#| label: los-quasi-poisson-model

los.qpoi <- glm(los ~ type + white + hmo + age.cat,
                data = db,
                family = quasipoisson(link = "log"))
summary(los.qpoi)
```

```{r}
#| inculde: false
#| label: los-clean-up-env-5

rm(los.qpoi)
```

```{r}
#| echo: true
#| label: los-poisson-model-with-provnum-fixed-effects

los.pois.provnum <- glm(los ~ type + white + hmo + age.cat + provnum,
                        data = db,
                        family = poisson(link = "log"))
(sm <- summary(los.pois.provnum))
```

```{r}
#| echo: true
#| label: los-compute-weights-by-provnum

wt <- db |>
  group_by(provnum) |>
  summarize(n.obs = n()) |>
  mutate(n.obs = n.obs / max(n.obs))

db2 <- left_join(db, wt, by = "provnum")

m0 <- glm(los ~ type + white + hmo + age.cat + provnum,
            data = db2,
            family = quasipoisson(link = "log"),
          weights = n.obs)
(sm0 <- summary(m0))
```

```{r}
#| echo: true
#| label: los-random-intercept-mixed-model

model.mu <- DHGLMMODELING(Model = "mean",
                          Link = "log",
                          LinPred = los ~ type + white + hmo + 
                            age.cat + (1 | provnum),
                          RandDist = "gamma")

model.phi <- DHGLMMODELING(Model = "dispersion")
```

```{r}
#| echo: true
#| label: los-random-intercept-mixed-model-fit

los.re <- dhglmfit(RespDist = "poisson",
                      DataMain = db,
                      MeanModel = model.mu,
                      DispersionModel = model.phi)
```

```{r}
#| include: true
#| label: los-gather-coefficients-3-models

tb <- tibble(var = c("Intercept", "Type Urgent", "Type Emergency",
                     "White", "HMO", "Age Group 1", "Age Group 2",
                     "Age Group 3", "Age Group 4", "Age Group 5",
                     "Age Group 7","Age Group 8", "Age Group 9"),
             los.pois.est = coef(sm)[1:13, 1],
             los.pois.se = coef(sm)[1:13, 2],
             los.pois.tstat = los.pois.est / los.pois.se,
             los.pois.sig = ifelse(abs(los.pois.tstat) > 1.96, "*", " "),
             los.pois.wt.est = coef(sm0)[1:13, 1],
             los.pois.wt.se = coef(sm0)[1:13, 2],
             los.pois.wt.tstat = los.pois.wt.est / los.pois.wt.se,
             los.pois.wt.sig = ifelse(abs(los.pois.wt.tstat) > 1.96, "*", " "),
             los.re.est = los.re$beta_coeff[,1],
             los.re.se = los.re$beta_coeff[,2],
             los.re.tstat = los.re.est / los.re.se,
             los.re.sig = ifelse(abs(los.re.tstat) > 1.96, "*", " "))
```

```{r}
#| echo: true
#| label: tbl-los-coefficients-3-models
#| tbl-cap: "Estimated coefficients and their t-values from three models that include `provnum` as an explanatory variable but whose coefficients are not shown. The models are Poisson, Weighted quasi-Poisson, and Poisson with random intercepts."

tb |>
  select(var, 
         los.pois.est, los.pois.tstat, los.pois.sig,
         los.pois.wt.est, los.pois.wt.tstat, los.pois.wt.sig,
         los.re.est, los.re.tstat, los.re.sig) |>
  kbl(booktabs = TRUE,
      col.names = c("Variable", rep(c("Est.", "t-stat", " "), 3)),
      digits = c(0, rep(c(3, 3, 0), 3))) |>
  add_header_above(c(" " = 1, "Poisson" = 3, 
                     "Wtd. quasi-Poisson" = 3, 
                     "Random Intercepts" = 3)) |>
  kable_classic()
```

```{r}
#| echo: true
#| label: los-compute-probability-of-dying-in-hospital

db |> 
  group_by(age.cat) |>
  summarize(n.dead = sum(died),
            n.patients = n(),
            prob.death = mean(died)) |>
  arrange(levels(age.cat))
```

```{r}
#| include: true
#| label: los-compute-random-intercept-fv-and-studentized-residuals

db2 <- db |>
  mutate(mu = los.re[7][[1]],
         SR = los.re[1][[1]])
```

```{r}
#| echo: true
#| message: false
#| label: fig-los-diagnostic-plots-random-intercept-model
#| fig-cap: "Diagnostic plots for the length of stay random intercept model by medical provider."

p1 <- ggplot(data = db2,
             mapping = aes(x = mu,
                           y = SR)) +
  geom_point(alpha = 0.3) + geom_smooth(se = FALSE) +
  labs(x = "Fitted Values (lin. pred. scale)",
       y = "Studentized Residuals")
p2 <- ggplot(data = db2,
             mapping = aes(x = mu,
                           y = abs(SR))) +
  geom_point(alpha = 0.3) + geom_smooth(se = FALSE) +
  labs(x = "Fitted Values (lin. pred. scale)",
       y = "|Studentized Residuals|")
p3 <- ggplot(data = db2,
             mapping = aes(sample = SR)) +
  geom_qq() + geom_qq_line() +
  labs(x = "Theoretical Quantiles",
       y = "Sample Quantiles")
p4 <- ggplot(data = db2,
             mapping = aes(x = SR)) +
  geom_histogram() +
  labs(x = "Studentized Residuals",
       y = "Frequency")
(p1 + p2) / (p3 + p4)
```

```{r}
#| include: false
#| label: los-clean-up-env-6

rm(db2, p1, p2, p3, p4)
```

```{r}
#| include: true
#| label: compute-los-random-effects-density-and-points

sigma <- exp(los.re$lambda_coeff[1,1])
alpha <- 1/sigma
dg <- tibble(x = as.vector(exp(los.re$v_h)),
             y = runif(length(x), min = 0, max = 0.02))
dh <- tibble(x = seq(0.01, 3.3, length = 500),
                     y = dgamma(x, shape = alpha, scale = sigma))
rm(sigma, alpha)
```

```{r}
#| echo: true
#| label: fig-los-random-effects-density-and-points
#| fig-cap: "The estimated density function for the intercept random effects along with the estimated medical provider random effects."

ggplot(data = dh,
       mapping = aes(x = x,
                     y = y)) +
  geom_line() +
  geom_point(data = dg,
             mapping = aes(x = x, y = y),
             alpha = 0.2) +
  labs(x = "Unobserved Gamma Random Variable",
       y = "Density")
rm(dg, dh)
```

```{r}
#| include: true
#| label: load-bus-data

bus <- read_csv("bus-case.csv",
                col_types = "fffnnnn")
```

```{r}
#| include: true
#| label: compute-bus-numerical-variables-summary

f <- function(data, variable) {
  ans <- data |>
    summarize(var = as_label(enquo(variable)),
              n = sum(!is.na({{variable}})),
              mn = mean({{variable}}, na.rm = TRUE),
              sd = sd({{variable}}, na.rm = TRUE),
              p25 = quantile({{variable}}, probs = 0.25, na.rm = TRUE),
              p50 = quantile({{variable}}, probs = 0.50, na.rm = TRUE),
              p75 = quantile({{variable}}, probs = 0.75, na.rm = TRUE),
              min = min({{variable}}, na.rm = TRUE),
              max = max({{variable}}, na.rm = TRUE))
  return(ans)
}

tb <- bind_rows(f(bus, no.obs),
                f(bus, dur),
                f(bus, clm.cnt),
                f(bus, tot.cost))
rm(f)
```

```{r}
#| echo: true
#| label: tbl-bus-assemble-numeric-variables-summary
#| tbl-cap: "Summary statistics for the numeric variables in the bus data set. Variable `no.obs` is the number of observations in a particualr tariff cell. Note that each renewal counts as one observation. Duration, `dur`, is measured in days. The variable `clm.cnt` is the number of claims and `tot.cost` is the total loss cost."

kbl(tb,
    booktabs = TRUE,
    digits = c(0,0,2,2,1,1,1,1,1),
    col.names = c("Variable", "Count", "Mean", "Std. Dev.", 
                  "25", "50", "75", "Min", "Max"),
    align = "lrrrrrrrr",
    format.args = list(big.mark = ","), nsmall = 1) |>
  add_header_above(c(" " = 1, " " = 1, " " = 1, " " = 1, "Percentiles" = 3,
                     " " = 1, " " = 1)) |>
  kable_classic()
rm(tb)
```

```{r}
#| include: true
#| label: bus-remove-negative-tot-cost-rows

idx <- pull(bus, tot.cost) >= 0
idx[is.na(idx)] <- TRUE
db <- bus[idx,]
rm(idx)
```

```{r}
#| echo: true
#| label: compute-bus-top-ten-claims

sort(pull(db, clm.cnt), decreasing = TRUE)[1:10]
```
The two largest ones, (402 and 377), come from company 145.
We suspect that these entries are erroneous and because we cannot go back
to the source systems or other sources of information to correct them we will
delete company 145 from our analysis.
This will remove a total of 
`r sum(pull(db, co.id) == "145")`
rows of data.

```{r}
#| include: true
#| label: remove-company-145

db <- db |>
  filter(co.id != "145")
```

```{r}
#| echo: true
#| label: fig-bus-histograms-numeric-variables
#| fig-cap: "Histograms of the numeric variables in the bus dataset. Note that all four of them are heavily skewed to the right and we have not shown all data points in order to enhance the display. For the number of bus observations, 30 observations greater than 100 are not shown. For duration, 26 observations greater than 20,000 are not displayed. Seven claim counts greater than 25 are not shown and 23 observations for total loss cost greater than 300,000 are also not shown."
#| warning: false

p1 <- ggplot(data = db,
       mapping = aes(x = no.obs)) +
  geom_histogram(bins = 50) +
  labs(x = "Number of Bus Observations",
       y = "Count") +
  coord_cartesian(xlim = c(0,100))

p2 <- ggplot(data = db,
       mapping = aes(x = dur)) +
  geom_histogram(bins = 50) +
  labs(x = "Duration (in days)",
       y = "Count") +
  scale_x_continuous(breaks = c(0, 5000, 10000, 15000, 20000),
                     labels = c("0", "5K", "10K", "15K", "20K")) +
  coord_cartesian(xlim = c(0,20000))

p3 <- ggplot(data = db,
       mapping = aes(x = clm.cnt)) +
  geom_histogram(bins = 50) +
  labs(x = "Number of Claims",
       y = "Count") +
  coord_cartesian(xlim = c(0,25))

p4 <- ggplot(data = db,
       mapping = aes(x = tot.cost)) +
  geom_histogram(bins = 50) +
  labs(x = "Total Loss Cost",
       y = "Count") +
  scale_x_continuous(breaks = c(0, 100000, 200000, 300000),
                     labels = c("0", "100K", "200K", "300K")) +
  coord_cartesian(xlim = c(0, 300000))

(p1 + p2) / (p3 + p4)
rm(p1, p2, p3, p4)
```

```{r}
#| echo: true
#| label: compute-bus-summary-of-claim-counts-by-zone-and-bus-age

db |> 
  group_by(zone, bus.age) |>
  summarize(clm.cnt = sum(clm.cnt),
            .groups = "drop") |>
  pivot_wider(names_from = bus.age,
              values_from = clm.cnt)
```

```{r}
#| echo: true
#| label: bus-summary-exposure-by-bus-age

db |> 
  group_by(zone, bus.age) |>
  summarize(expo = sum(dur),
            .groups = "drop") |>
  pivot_wider(names_from = bus.age,
              values_from = expo)
```

```{r}
#| include: true
#| label: compute-bus-empirical-frequency

tb <- db |>
  group_by(zone, bus.age) |>
  summarize(sz = n(),
            dur.yrs = sum(dur),
            clm.cnt = sum(clm.cnt),
            fq = clm.cnt / dur.yrs * 365,
            .groups = "drop")
tbl <- tb |>
  select(zone, bus.age, fq) |>
  pivot_wider(names_from = "bus.age",
              values_from = fq)
```

```{r}
#| echo: true
#| label: tbl-bus-zone-age-empirical-frequency
#| tbl-cap: "Empirical frequency (per year of exposure) for the bus dataset by geographic zone and age class of the bus."

kbl(tbl,
    booktabs = TRUE,
    digits = 3,
    align = "crrrrr") |>
  add_header_above(c(" " = 1, "Bus Age Class" =  5)) |>
  kable_classic()
```

```{r}
#| echo: true
#| label: tbl-bus-zone-1-age-0-frequency-by-record
#| tbl-cap: "Observations available for zone 1 and bus age category 0 along with the empirical annual frequency for each company. The overall annual frequency for this cell is equal to 0.726."

db |>
  select(zone, bus.age, co.id, dur, clm.cnt) |>
  filter(zone == "1",
         bus.age == "0") |>
  mutate(freq = clm.cnt / dur * 365) |>
  arrange(desc(freq), dur) |>
  kbl(booktabs = TRUE,
      col.names = c("Zone", "Bus Age", "Company", "Duration", 
                    "Claim Count", "Frequency"),
      digits = c(0,0,0,0,0,3),
      align = "cccrrr") |>
  kable_classic()
```

```{r}
#| echo: true
#| label: bus-frequency-model-zone-and-bus-age

fq.poi <- glm(clm.cnt ~ zone + bus.age,
              data = db,
              family = poisson(link = "log"),
              offset = log(dur))
summary(fq.poi)
```

```{r}
#| echo: true
#| label: bus-compute-mean-deviance-dispersion-parameter

round(deviance(fq.poi) / df.residual(fq.poi), 3)
```

```{r}
#| echo: true
#| label: bus-compute-pearson-dispersion-parameter

round(sum(resid(fq.poi, type = "pearson")^2) / 
        df.residual(fq.poi), 3)
```

```{r}
#| echo: true
#| label: compute-bus-relevel-zone-and-bus-age

db$zone.f <- fct_relevel(db$zone, "4")
db$bus.age.f <- fct_relevel(db$bus.age, "4")
```

```{r}
#| echo: true
#| label: compute-bus-nb-model-zone-bus-age

fq.nb <- glm.nb(clm.cnt ~ zone.f + bus.age.f + offset(log(dur)),
                data = db)
summary(fq.nb)
```

```{r}
#| include: true
#| label: compute-bus-data-for-predictions

df <- expand_grid(zone.f = factor(1:7),
                  bus.age.f = factor(0:4))
df$dur <- 365
```

```{r}
#| echo: true
#| label: tbl-bus-nb-model-predictions
#| tbl-cap: "Annual mean frequency predictions from the negative binomial model with main effects for geographic zone and bus age class."

df <- df |>
  mutate(nb.mu = predict(fq.nb, newdata = df, type = "response"))
df |>
  select(zone.f, bus.age.f, nb.mu) |>
  pivot_wider(names_from = bus.age.f,
              values_from = nb.mu) |>
  kbl(booktabs = TRUE,
      col.names = c("Zone", "0", "1", "2", "3", "4"),
      digits = c(0, 3, 3, 3, 3, 3),
      align = "cccrrr") |>
  add_header_above(c(" " = 1, "Bus Age Class" = 5)) |>
  kable_classic()
```

```{r}
#| echo: true
#| label: define-bus-glmm-zone-bus-age-model

model.mu <- DHGLMMODELING(Model = "mean",
                          Link = "log",
                          LinPred = clm.cnt ~ zone.f + bus.age.f + 
                            (1 | co.id),
                          RandDist = "gamma",
                          Offset = log(db$dur))

model.phi <- DHGLMMODELING(Model = "dispersion")
```

```{r}
#| echo: true
#| label: compute-bus-estimates-of-glmm-model
#| cache: true

fq.poi.re <- dhglmfit(RespDist = "poisson",
                      DataMain = db,
                      MeanModel = model.mu,
                      DispersionModel = model.phi)
```

```{r}
#| include: true
#| label: compute-bus-random-effects-density-and-points

sigma <- exp(fq.poi.re$lambda_coeff[1,1])
alpha <- 1/sigma
dg <- tibble(x = exp(fq.poi.re$v_h),
             y = runif(length(x), min = 0, max = 0.02))
dh <- tibble(x = seq(0.01, 3.2, length = 500),
                     y = dgamma(x, shape = alpha, scale = sigma))
rm(sigma, alpha)
```

```{r}
#| echo: true
#| label: fig-bus-random-effects-density-and-points
#| fig-cap: "The estimated density function for the intercept random effects along with the individual estimated company effects."

ggplot(data = dh,
       mapping = aes(x = x,
                     y = y)) +
  geom_line() +
  geom_point(data = dg,
             mapping = aes(x = x, y = y),
             alpha = 0.2) +
  labs(x = "Unobserved Gamma Random Variable",
       y = "Density")
rm(dg, dh)
```

```{r}
#| echo: true
#| label: tbl-bus-top-5-estimated-random-effects
#| tbl-cap: "Empirical annual frequency and estimated random effect for the top five companies ranked on the size of their random effect."

db |>
  group_by(co.id) |>
  summarize(clm.cnt = sum(clm.cnt),
            dur = sum(dur)) |>
  mutate(ran.ef = exp(fq.poi.re[["v_h"]][,1])) |>
  select(co.id, clm.cnt, dur, ran.ef) |>
  mutate(freq = clm.cnt / dur * 365) |>
  select(co.id, clm.cnt, dur, freq, ran.ef) |>
  arrange(desc(ran.ef)) |>
  slice(1:5) |>
  kbl(booktabs = TRUE,
      col.names = c("Company", "of Claims", "(in days)", 
                    "Frequency", "Effect"),
      digits = c(0, 0, 0, 3, 3),
      align = "crrrr",
      format.args = list(big.mark = ",")) |>
  add_header_above(c(" " = 1, "Number" = 1, "Exposure" = 1, 
                     "Annual" = 1, "Random" = 1),
                   align = rep("r", 5),
                   line = FALSE) |>
  kable_classic()
```

```{r}
#| include: true
#| label: compute-bus-fixed-effect-annual-frequency

cf <- fq.poi.re$beta_coeff[,1]
zn <- c(cf[2:4], zone.f4 = 0, cf[5:7])
ba <- c(cf[8:11], bus.age.f4 = 0)
m <- exp(cf[1]) * outer(exp(zn), exp(ba)) * 365
dimnames(m) <- list(str_c("Zone ", 1:7), str_c("Bus Age ", 0:4))
rm(cf, zn, ba)
```

```{r}
#| echo: true
#| label: tbl-bus-fixed-effects-annual-frequency-component
#| tbl-cap: "Estimated annual frequency based only on the fixed effects from the generalized linear mixed model."

fe.tbl <- bind_cols("Zone" = 1:7, as_tibble(m))
fe.tbl |>
  kbl(booktabs = TRUE,
      col.names = c("Zone", 0:4),
      digits = c(0, 3, 3, 3, 3, 3),
      align = "crrrrr") |>
  add_header_above(c(" " = 1, "Bus Age Category" = 5)) |>
  kable_classic()
rm(fe.tbl, m)
```

```{r}
#| include: true
#| label: compute-bus-sample-random-effects

rn.ef <- exp(fq.poi.re$v_h[,1])
ord <- order(rn.ef)
rn.ef <- rn.ef[ord]
nms <- as.numeric(dimnames(fq.poi.re$v_h)[[1]])[ord]
tbl <- bind_cols(co1 = nms[1:10],
                 re1 = rn.ef[1:10],
                 co2 = nms[325:334],
                 re2 = rn.ef[325:334],
                 co3 = nms[651:660],
                 re3 = rn.ef[651:660])
rm(rn.ef, ord, nms)
```

```{r}
#| echo: true
#| label: tbl-bus-sample-company-random-effects
#| tbl-cap: "Estimated company random effects. Companies have been sorted from smallest to largest random effects."

tbl |>
  kbl(booktabs = TRUE,
      col.names = rep(c("Company", "Effect"), 3),
      digits = rep(c(0, 3), 3),
      align = "crcrcr") |>
  add_header_above(rep(c(" " = 1, "Random" = 1), 3),
                   line = FALSE) |>
  add_header_above(c("Smallest" = 2, "Medium" = 2, "Largest" = 2)) |>
  kable_classic()
rm(tbl)
```

```{r}
#| include: true
#| label: compute-bus-duration-random-effects-by-company

dc <- db |>
  group_by(co.id) |>
  summarize(clm.cnt = sum(clm.cnt),
            dur = sum(dur)) |>
  mutate(ran.ef = exp(fq.poi.re[["v_h"]][,1]),
         freq = clm.cnt / dur * 365)
```

```{r}
#| echo: true
#| label: fig-bus-duration-random-effects-claim-counts-by-company
#| fig-cap: "Total company exposure and claim counts along with the estimated company random effect."

ggplot(data = dc,
       mapping = aes(y = dur,
                     x = ran.ef,
                     size = clm.cnt)) +
  geom_point(alpha = 0.2) +
  labs(x = "Estimated Random Effect",
       y = "Total Company Exposure (in days)") +
  scale_size_continuous(guide = guide_legend(title = "Total Claim Count")) +
  theme(legend.position = "bottom")
rm(dc)
```

